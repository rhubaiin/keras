{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081252ec",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:07.446183Z",
     "iopub.status.busy": "2024-10-06T08:43:07.445557Z",
     "iopub.status.idle": "2024-10-06T08:43:38.956347Z",
     "shell.execute_reply": "2024-10-06T08:43:38.955084Z"
    },
    "papermill": {
     "duration": 31.527018,
     "end_time": "2024-10-06T08:43:38.959374",
     "exception": false,
     "start_time": "2024-10-06T08:43:07.432356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.17 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "US1_J2KR.dcm:   0%|          | 38.0/154k [00:00<01:15, 2.03kB/s]\n",
      "MR-SIEMENS-DICOM-WithOverlays.dcm:   0%|          | 125/511k [00:00<01:48, 4.72kB/s]\n",
      "OBXXXX1A.dcm:   0%|          | 119/486k [00:00<01:39, 4.89kB/s]\n",
      "US1_UNCR.dcm:   0%|          | 226/923k [00:00<02:35, 5.93kB/s]\n",
      "color3d_jpeg_baseline.dcm:   0%|          | 1.50k/6.14M [00:00<07:04, 14.5kB/s]\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "import pydicom\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader  # Import Dataset here\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a7a288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:38.982239Z",
     "iopub.status.busy": "2024-10-06T08:43:38.981672Z",
     "iopub.status.idle": "2024-10-06T08:43:38.995976Z",
     "shell.execute_reply": "2024-10-06T08:43:38.994666Z"
    },
    "papermill": {
     "duration": 0.029108,
     "end_time": "2024-10-06T08:43:38.998948",
     "exception": false,
     "start_time": "2024-10-06T08:43:38.969840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b09d1a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.022351Z",
     "iopub.status.busy": "2024-10-06T08:43:39.021776Z",
     "iopub.status.idle": "2024-10-06T08:43:39.290561Z",
     "shell.execute_reply": "2024-10-06T08:43:39.289348Z"
    },
    "papermill": {
     "duration": 0.28398,
     "end_time": "2024-10-06T08:43:39.293839",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.009859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Below is working se\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the necessary CSV files\n",
    "df_train = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\n",
    "df_train_label = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv\")\n",
    "df_train_series = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\")\n",
    "df_train = df_train.fillna(0.0)\n",
    "# Merge the DataFrames for labels and series descriptions\n",
    "df_labels = pd.merge(df_train_label, df_train_series, on=['study_id', 'series_id'])\n",
    "\n",
    "# Define the custom order for series_description\n",
    "order = ['Sagittal T2/STIR', 'Sagittal T1', 'Axial T2']\n",
    "\n",
    "# Convert the series_description column to a categorical type with the custom order\n",
    "df_labels['series_description'] = pd.Categorical(df_labels['series_description'], \n",
    "                                                 categories=order, \n",
    "                                                 ordered=True)\n",
    "\n",
    "# Sort the DataFrame by study_id and series_description (following the custom order)\n",
    "df_labels_sorted = df_labels.sort_values(by=['study_id', 'series_description']).reset_index(drop=True)\n",
    "\n",
    "# Filter out rows with missing or invalid bounding box coordinates AFTER sorting\n",
    "df_labels_filtered = df_labels_sorted.dropna(subset=['x', 'y'])\n",
    "df_labels_filtered = df_labels_filtered[(df_labels_filtered['x'] != 0) & (df_labels_filtered['y'] != 0)]\n",
    "\n",
    "# Path to the folder containing DICOM images\n",
    "train_images = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a39c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.316716Z",
     "iopub.status.busy": "2024-10-06T08:43:39.316194Z",
     "iopub.status.idle": "2024-10-06T08:43:39.345555Z",
     "shell.execute_reply": "2024-10-06T08:43:39.343924Z"
    },
    "papermill": {
     "duration": 0.044704,
     "end_time": "2024-10-06T08:43:39.348962",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.304258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>322.831858</td>\n",
       "      <td>227.964602</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>320.571429</td>\n",
       "      <td>295.714286</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>323.030303</td>\n",
       "      <td>371.818182</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L4/L5</td>\n",
       "      <td>335.292035</td>\n",
       "      <td>427.327434</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L5/S1</td>\n",
       "      <td>353.415929</td>\n",
       "      <td>483.964602</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48687</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3390218084</td>\n",
       "      <td>10</td>\n",
       "      <td>Right Subarticular Stenosis</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>302.875911</td>\n",
       "      <td>356.304937</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48688</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3390218084</td>\n",
       "      <td>15</td>\n",
       "      <td>Left Subarticular Stenosis</td>\n",
       "      <td>L4/L5</td>\n",
       "      <td>348.203719</td>\n",
       "      <td>341.369400</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48689</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3390218084</td>\n",
       "      <td>15</td>\n",
       "      <td>Right Subarticular Stenosis</td>\n",
       "      <td>L4/L5</td>\n",
       "      <td>305.745866</td>\n",
       "      <td>340.520184</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48690</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3390218084</td>\n",
       "      <td>20</td>\n",
       "      <td>Left Subarticular Stenosis</td>\n",
       "      <td>L5/S1</td>\n",
       "      <td>355.777684</td>\n",
       "      <td>368.960270</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48691</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>3390218084</td>\n",
       "      <td>21</td>\n",
       "      <td>Right Subarticular Stenosis</td>\n",
       "      <td>L5/S1</td>\n",
       "      <td>302.875911</td>\n",
       "      <td>364.627811</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48692 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id   series_id  instance_number                    condition  \\\n",
       "0         4003253   702807833                8        Spinal Canal Stenosis   \n",
       "1         4003253   702807833                8        Spinal Canal Stenosis   \n",
       "2         4003253   702807833                8        Spinal Canal Stenosis   \n",
       "3         4003253   702807833                8        Spinal Canal Stenosis   \n",
       "4         4003253   702807833                8        Spinal Canal Stenosis   \n",
       "...           ...         ...              ...                          ...   \n",
       "48687  4290709089  3390218084               10  Right Subarticular Stenosis   \n",
       "48688  4290709089  3390218084               15   Left Subarticular Stenosis   \n",
       "48689  4290709089  3390218084               15  Right Subarticular Stenosis   \n",
       "48690  4290709089  3390218084               20   Left Subarticular Stenosis   \n",
       "48691  4290709089  3390218084               21  Right Subarticular Stenosis   \n",
       "\n",
       "       level           x           y series_description  \n",
       "0      L1/L2  322.831858  227.964602   Sagittal T2/STIR  \n",
       "1      L2/L3  320.571429  295.714286   Sagittal T2/STIR  \n",
       "2      L3/L4  323.030303  371.818182   Sagittal T2/STIR  \n",
       "3      L4/L5  335.292035  427.327434   Sagittal T2/STIR  \n",
       "4      L5/S1  353.415929  483.964602   Sagittal T2/STIR  \n",
       "...      ...         ...         ...                ...  \n",
       "48687  L3/L4  302.875911  356.304937           Axial T2  \n",
       "48688  L4/L5  348.203719  341.369400           Axial T2  \n",
       "48689  L4/L5  305.745866  340.520184           Axial T2  \n",
       "48690  L5/S1  355.777684  368.960270           Axial T2  \n",
       "48691  L5/S1  302.875911  364.627811           Axial T2  \n",
       "\n",
       "[48692 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this arranges all the series description in order, and displays the relevant images which have bounding boxes with x,y\n",
    "df_labels_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4323458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.373073Z",
     "iopub.status.busy": "2024-10-06T08:43:39.371792Z",
     "iopub.status.idle": "2024-10-06T08:43:39.393743Z",
     "shell.execute_reply": "2024-10-06T08:43:39.392419Z"
    },
    "papermill": {
     "duration": 0.037281,
     "end_time": "2024-10-06T08:43:39.396855",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.359574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the first 30 unique study_ids\n",
    "first_20_study_ids = df_labels_filtered['study_id'].unique()[:20]\n",
    "\n",
    "# Filter df_labels_filtered to keep only rows with the first 30 study_ids while retaining all columns\n",
    "df_series_20 = df_labels_filtered[df_labels_filtered['study_id'].isin(first_20_study_ids)]\n",
    "\n",
    "# Save the filtered DataFrame with all columns to a new CSV file\n",
    "df_series_20.to_csv('df_first_20_study_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c08a82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.419800Z",
     "iopub.status.busy": "2024-10-06T08:43:39.419245Z",
     "iopub.status.idle": "2024-10-06T08:43:39.441273Z",
     "shell.execute_reply": "2024-10-06T08:43:39.439882Z"
    },
    "papermill": {
     "duration": 0.037038,
     "end_time": "2024-10-06T08:43:39.444264",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.407226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>322.831858</td>\n",
       "      <td>227.964602</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>320.571429</td>\n",
       "      <td>295.714286</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>323.030303</td>\n",
       "      <td>371.818182</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L4/L5</td>\n",
       "      <td>335.292035</td>\n",
       "      <td>427.327434</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>8</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>L5/S1</td>\n",
       "      <td>353.415929</td>\n",
       "      <td>483.964602</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>53418228</td>\n",
       "      <td>1921001089</td>\n",
       "      <td>17</td>\n",
       "      <td>Right Subarticular Stenosis</td>\n",
       "      <td>L3/L4</td>\n",
       "      <td>131.597663</td>\n",
       "      <td>139.623736</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>53418228</td>\n",
       "      <td>1921001089</td>\n",
       "      <td>23</td>\n",
       "      <td>Left Subarticular Stenosis</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>161.723884</td>\n",
       "      <td>144.257143</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>53418228</td>\n",
       "      <td>1921001089</td>\n",
       "      <td>23</td>\n",
       "      <td>Right Subarticular Stenosis</td>\n",
       "      <td>L2/L3</td>\n",
       "      <td>137.661660</td>\n",
       "      <td>147.304799</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>53418228</td>\n",
       "      <td>1921001089</td>\n",
       "      <td>29</td>\n",
       "      <td>Left Subarticular Stenosis</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>164.638170</td>\n",
       "      <td>151.057143</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>53418228</td>\n",
       "      <td>1921001089</td>\n",
       "      <td>29</td>\n",
       "      <td>Right Subarticular Stenosis</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>142.917124</td>\n",
       "      <td>155.794395</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     study_id   series_id  instance_number                    condition  \\\n",
       "0     4003253   702807833                8        Spinal Canal Stenosis   \n",
       "1     4003253   702807833                8        Spinal Canal Stenosis   \n",
       "2     4003253   702807833                8        Spinal Canal Stenosis   \n",
       "3     4003253   702807833                8        Spinal Canal Stenosis   \n",
       "4     4003253   702807833                8        Spinal Canal Stenosis   \n",
       "..        ...         ...              ...                          ...   \n",
       "491  53418228  1921001089               17  Right Subarticular Stenosis   \n",
       "492  53418228  1921001089               23   Left Subarticular Stenosis   \n",
       "493  53418228  1921001089               23  Right Subarticular Stenosis   \n",
       "494  53418228  1921001089               29   Left Subarticular Stenosis   \n",
       "495  53418228  1921001089               29  Right Subarticular Stenosis   \n",
       "\n",
       "     level           x           y series_description  \n",
       "0    L1/L2  322.831858  227.964602   Sagittal T2/STIR  \n",
       "1    L2/L3  320.571429  295.714286   Sagittal T2/STIR  \n",
       "2    L3/L4  323.030303  371.818182   Sagittal T2/STIR  \n",
       "3    L4/L5  335.292035  427.327434   Sagittal T2/STIR  \n",
       "4    L5/S1  353.415929  483.964602   Sagittal T2/STIR  \n",
       "..     ...         ...         ...                ...  \n",
       "491  L3/L4  131.597663  139.623736           Axial T2  \n",
       "492  L2/L3  161.723884  144.257143           Axial T2  \n",
       "493  L2/L3  137.661660  147.304799           Axial T2  \n",
       "494  L1/L2  164.638170  151.057143           Axial T2  \n",
       "495  L1/L2  142.917124  155.794395           Axial T2  \n",
       "\n",
       "[496 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_series_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a659b723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.469180Z",
     "iopub.status.busy": "2024-10-06T08:43:39.468747Z",
     "iopub.status.idle": "2024-10-06T08:43:39.474753Z",
     "shell.execute_reply": "2024-10-06T08:43:39.473201Z"
    },
    "papermill": {
     "duration": 0.021392,
     "end_time": "2024-10-06T08:43:39.477569",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.456177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get images with that only contain instance number in df_labels_fltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c505619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.502654Z",
     "iopub.status.busy": "2024-10-06T08:43:39.502059Z",
     "iopub.status.idle": "2024-10-06T08:43:39.508342Z",
     "shell.execute_reply": "2024-10-06T08:43:39.506907Z"
    },
    "papermill": {
     "duration": 0.022177,
     "end_time": "2024-10-06T08:43:39.511186",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.489009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get train_csv that only has study_id in df_labels_fltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d526b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.535953Z",
     "iopub.status.busy": "2024-10-06T08:43:39.535321Z",
     "iopub.status.idle": "2024-10-06T08:43:39.578580Z",
     "shell.execute_reply": "2024-10-06T08:43:39.577127Z"
    },
    "papermill": {
     "duration": 0.059284,
     "end_time": "2024-10-06T08:43:39.581699",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.522415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11340341</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11943292</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13317052</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22191399</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26342422</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29931867</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33736057</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38281420</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40745534</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41477684</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44060036</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46494080</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>52397721</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>52695609</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53418228</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    study_id spinal_canal_stenosis_l1_l2 spinal_canal_stenosis_l2_l3  \\\n",
       "0    4003253                 Normal/Mild                 Normal/Mild   \n",
       "1    4646740                 Normal/Mild                 Normal/Mild   \n",
       "2    7143189                 Normal/Mild                 Normal/Mild   \n",
       "3    8785691                 Normal/Mild                 Normal/Mild   \n",
       "4   10728036                 Normal/Mild                 Normal/Mild   \n",
       "5   11340341                 Normal/Mild                 Normal/Mild   \n",
       "6   11943292                 Normal/Mild                 Normal/Mild   \n",
       "7   13317052                 Normal/Mild                 Normal/Mild   \n",
       "8   22191399                 Normal/Mild                 Normal/Mild   \n",
       "9   26342422                 Normal/Mild                 Normal/Mild   \n",
       "10  29931867                 Normal/Mild                    Moderate   \n",
       "11  33736057                 Normal/Mild                 Normal/Mild   \n",
       "12  38281420                 Normal/Mild                 Normal/Mild   \n",
       "13  40745534                 Normal/Mild                 Normal/Mild   \n",
       "14  41477684                 Normal/Mild                    Moderate   \n",
       "15  44060036                 Normal/Mild                 Normal/Mild   \n",
       "16  46494080                 Normal/Mild                 Normal/Mild   \n",
       "17  52397721                 Normal/Mild                      Severe   \n",
       "18  52695609                 Normal/Mild                    Moderate   \n",
       "19  53418228                 Normal/Mild                 Normal/Mild   \n",
       "\n",
       "   spinal_canal_stenosis_l3_l4 spinal_canal_stenosis_l4_l5  \\\n",
       "0                  Normal/Mild                 Normal/Mild   \n",
       "1                     Moderate                      Severe   \n",
       "2                  Normal/Mild                 Normal/Mild   \n",
       "3                  Normal/Mild                 Normal/Mild   \n",
       "4                  Normal/Mild                 Normal/Mild   \n",
       "5                  Normal/Mild                 Normal/Mild   \n",
       "6                  Normal/Mild                 Normal/Mild   \n",
       "7                  Normal/Mild                 Normal/Mild   \n",
       "8                  Normal/Mild                      Severe   \n",
       "9                  Normal/Mild                 Normal/Mild   \n",
       "10                    Moderate                 Normal/Mild   \n",
       "11                 Normal/Mild                 Normal/Mild   \n",
       "12                 Normal/Mild                    Moderate   \n",
       "13                    Moderate                      Severe   \n",
       "14                    Moderate                      Severe   \n",
       "15                 Normal/Mild                 Normal/Mild   \n",
       "16                    Moderate                 Normal/Mild   \n",
       "17                      Severe                    Moderate   \n",
       "18                    Moderate                 Normal/Mild   \n",
       "19                 Normal/Mild                 Normal/Mild   \n",
       "\n",
       "   spinal_canal_stenosis_l5_s1 left_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                  Normal/Mild                           Normal/Mild   \n",
       "1                  Normal/Mild                           Normal/Mild   \n",
       "2                  Normal/Mild                           Normal/Mild   \n",
       "3                  Normal/Mild                           Normal/Mild   \n",
       "4                  Normal/Mild                           Normal/Mild   \n",
       "5                  Normal/Mild                           Normal/Mild   \n",
       "6                  Normal/Mild                           Normal/Mild   \n",
       "7                  Normal/Mild                           Normal/Mild   \n",
       "8                  Normal/Mild                           Normal/Mild   \n",
       "9                  Normal/Mild                           Normal/Mild   \n",
       "10                 Normal/Mild                           Normal/Mild   \n",
       "11                 Normal/Mild                           Normal/Mild   \n",
       "12                 Normal/Mild                           Normal/Mild   \n",
       "13                 Normal/Mild                           Normal/Mild   \n",
       "14                 Normal/Mild                           Normal/Mild   \n",
       "15                 Normal/Mild                           Normal/Mild   \n",
       "16                 Normal/Mild                           Normal/Mild   \n",
       "17                 Normal/Mild                           Normal/Mild   \n",
       "18                 Normal/Mild                           Normal/Mild   \n",
       "19                 Normal/Mild                           Normal/Mild   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l2_l3  \\\n",
       "0                            Normal/Mild   \n",
       "1                            Normal/Mild   \n",
       "2                            Normal/Mild   \n",
       "3                            Normal/Mild   \n",
       "4                            Normal/Mild   \n",
       "5                            Normal/Mild   \n",
       "6                            Normal/Mild   \n",
       "7                            Normal/Mild   \n",
       "8                            Normal/Mild   \n",
       "9                            Normal/Mild   \n",
       "10                           Normal/Mild   \n",
       "11                           Normal/Mild   \n",
       "12                           Normal/Mild   \n",
       "13                           Normal/Mild   \n",
       "14                           Normal/Mild   \n",
       "15                           Normal/Mild   \n",
       "16                           Normal/Mild   \n",
       "17                           Normal/Mild   \n",
       "18                              Moderate   \n",
       "19                           Normal/Mild   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l3_l4  \\\n",
       "0                            Normal/Mild   \n",
       "1                            Normal/Mild   \n",
       "2                            Normal/Mild   \n",
       "3                            Normal/Mild   \n",
       "4                            Normal/Mild   \n",
       "5                            Normal/Mild   \n",
       "6                            Normal/Mild   \n",
       "7                            Normal/Mild   \n",
       "8                            Normal/Mild   \n",
       "9                            Normal/Mild   \n",
       "10                           Normal/Mild   \n",
       "11                           Normal/Mild   \n",
       "12                           Normal/Mild   \n",
       "13                           Normal/Mild   \n",
       "14                              Moderate   \n",
       "15                           Normal/Mild   \n",
       "16                           Normal/Mild   \n",
       "17                           Normal/Mild   \n",
       "18                              Moderate   \n",
       "19                           Normal/Mild   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l4_l5  ...  \\\n",
       "0                               Moderate  ...   \n",
       "1                               Moderate  ...   \n",
       "2                            Normal/Mild  ...   \n",
       "3                               Moderate  ...   \n",
       "4                            Normal/Mild  ...   \n",
       "5                            Normal/Mild  ...   \n",
       "6                            Normal/Mild  ...   \n",
       "7                               Moderate  ...   \n",
       "8                            Normal/Mild  ...   \n",
       "9                            Normal/Mild  ...   \n",
       "10                              Moderate  ...   \n",
       "11                           Normal/Mild  ...   \n",
       "12                              Moderate  ...   \n",
       "13                              Moderate  ...   \n",
       "14                              Moderate  ...   \n",
       "15                           Normal/Mild  ...   \n",
       "16                           Normal/Mild  ...   \n",
       "17                              Moderate  ...   \n",
       "18                              Moderate  ...   \n",
       "19                           Normal/Mild  ...   \n",
       "\n",
       "   left_subarticular_stenosis_l1_l2 left_subarticular_stenosis_l2_l3  \\\n",
       "0                       Normal/Mild                      Normal/Mild   \n",
       "1                       Normal/Mild                      Normal/Mild   \n",
       "2                       Normal/Mild                      Normal/Mild   \n",
       "3                       Normal/Mild                      Normal/Mild   \n",
       "4                       Normal/Mild                      Normal/Mild   \n",
       "5                       Normal/Mild                      Normal/Mild   \n",
       "6                       Normal/Mild                      Normal/Mild   \n",
       "7                       Normal/Mild                      Normal/Mild   \n",
       "8                       Normal/Mild                      Normal/Mild   \n",
       "9                       Normal/Mild                      Normal/Mild   \n",
       "10                      Normal/Mild                      Normal/Mild   \n",
       "11                      Normal/Mild                      Normal/Mild   \n",
       "12                      Normal/Mild                      Normal/Mild   \n",
       "13                      Normal/Mild                      Normal/Mild   \n",
       "14                         Moderate                         Moderate   \n",
       "15                      Normal/Mild                      Normal/Mild   \n",
       "16                              0.0                              0.0   \n",
       "17                      Normal/Mild                         Moderate   \n",
       "18                      Normal/Mild                         Moderate   \n",
       "19                      Normal/Mild                      Normal/Mild   \n",
       "\n",
       "   left_subarticular_stenosis_l3_l4 left_subarticular_stenosis_l4_l5  \\\n",
       "0                       Normal/Mild                         Moderate   \n",
       "1                       Normal/Mild                           Severe   \n",
       "2                       Normal/Mild                      Normal/Mild   \n",
       "3                       Normal/Mild                      Normal/Mild   \n",
       "4                       Normal/Mild                      Normal/Mild   \n",
       "5                          Moderate                         Moderate   \n",
       "6                       Normal/Mild                      Normal/Mild   \n",
       "7                       Normal/Mild                      Normal/Mild   \n",
       "8                       Normal/Mild                         Moderate   \n",
       "9                       Normal/Mild                      Normal/Mild   \n",
       "10                         Moderate                         Moderate   \n",
       "11                      Normal/Mild                      Normal/Mild   \n",
       "12                      Normal/Mild                      Normal/Mild   \n",
       "13                         Moderate                           Severe   \n",
       "14                           Severe                           Severe   \n",
       "15                      Normal/Mild                      Normal/Mild   \n",
       "16                      Normal/Mild                         Moderate   \n",
       "17                         Moderate                           Severe   \n",
       "18                         Moderate                         Moderate   \n",
       "19                      Normal/Mild                      Normal/Mild   \n",
       "\n",
       "   left_subarticular_stenosis_l5_s1 right_subarticular_stenosis_l1_l2  \\\n",
       "0                       Normal/Mild                       Normal/Mild   \n",
       "1                       Normal/Mild                       Normal/Mild   \n",
       "2                       Normal/Mild                       Normal/Mild   \n",
       "3                       Normal/Mild                       Normal/Mild   \n",
       "4                       Normal/Mild                       Normal/Mild   \n",
       "5                       Normal/Mild                       Normal/Mild   \n",
       "6                          Moderate                       Normal/Mild   \n",
       "7                       Normal/Mild                       Normal/Mild   \n",
       "8                          Moderate                       Normal/Mild   \n",
       "9                       Normal/Mild                       Normal/Mild   \n",
       "10                         Moderate                          Moderate   \n",
       "11                      Normal/Mild                       Normal/Mild   \n",
       "12                      Normal/Mild                       Normal/Mild   \n",
       "13                         Moderate                       Normal/Mild   \n",
       "14                      Normal/Mild                       Normal/Mild   \n",
       "15                      Normal/Mild                       Normal/Mild   \n",
       "16                         Moderate                               0.0   \n",
       "17                      Normal/Mild                       Normal/Mild   \n",
       "18                      Normal/Mild                       Normal/Mild   \n",
       "19                      Normal/Mild                       Normal/Mild   \n",
       "\n",
       "   right_subarticular_stenosis_l2_l3 right_subarticular_stenosis_l3_l4  \\\n",
       "0                        Normal/Mild                       Normal/Mild   \n",
       "1                           Moderate                          Moderate   \n",
       "2                        Normal/Mild                       Normal/Mild   \n",
       "3                        Normal/Mild                       Normal/Mild   \n",
       "4                        Normal/Mild                       Normal/Mild   \n",
       "5                        Normal/Mild                          Moderate   \n",
       "6                        Normal/Mild                       Normal/Mild   \n",
       "7                        Normal/Mild                          Moderate   \n",
       "8                        Normal/Mild                       Normal/Mild   \n",
       "9                        Normal/Mild                       Normal/Mild   \n",
       "10                            Severe                            Severe   \n",
       "11                       Normal/Mild                       Normal/Mild   \n",
       "12                          Moderate                          Moderate   \n",
       "13                       Normal/Mild                          Moderate   \n",
       "14                          Moderate                            Severe   \n",
       "15                       Normal/Mild                          Moderate   \n",
       "16                               0.0                          Moderate   \n",
       "17                       Normal/Mild                            Severe   \n",
       "18                          Moderate                       Normal/Mild   \n",
       "19                       Normal/Mild                       Normal/Mild   \n",
       "\n",
       "   right_subarticular_stenosis_l4_l5 right_subarticular_stenosis_l5_s1  \n",
       "0                        Normal/Mild                       Normal/Mild  \n",
       "1                           Moderate                       Normal/Mild  \n",
       "2                        Normal/Mild                       Normal/Mild  \n",
       "3                        Normal/Mild                       Normal/Mild  \n",
       "4                           Moderate                       Normal/Mild  \n",
       "5                           Moderate                       Normal/Mild  \n",
       "6                        Normal/Mild                       Normal/Mild  \n",
       "7                           Moderate                          Moderate  \n",
       "8                             Severe                          Moderate  \n",
       "9                        Normal/Mild                       Normal/Mild  \n",
       "10                          Moderate                            Severe  \n",
       "11                       Normal/Mild                       Normal/Mild  \n",
       "12                            Severe                            Severe  \n",
       "13                            Severe                       Normal/Mild  \n",
       "14                            Severe                       Normal/Mild  \n",
       "15                          Moderate                       Normal/Mild  \n",
       "16                          Moderate                       Normal/Mild  \n",
       "17                            Severe                       Normal/Mild  \n",
       "18                          Moderate                       Normal/Mild  \n",
       "19                       Normal/Mild                       Normal/Mild  \n",
       "\n",
       "[20 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter df_train by matching study_ids in df_series_30\n",
    "df_train_20 = df_train[df_train['study_id'].isin(df_series_20['study_id'].unique())]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "df_train_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64dca99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.608994Z",
     "iopub.status.busy": "2024-10-06T08:43:39.608499Z",
     "iopub.status.idle": "2024-10-06T08:43:39.617131Z",
     "shell.execute_reply": "2024-10-06T08:43:39.615427Z"
    },
    "papermill": {
     "duration": 0.026258,
     "end_time": "2024-10-06T08:43:39.620326",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.594068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Map categories to integers\n",
    "label_map = {'Normal/Mild': 0.0, 'Moderate': 1.0, 'Severe': 2.0}\n",
    "\n",
    "# Convert targets in train.csv to numeric form\n",
    "def prepare_labels(train_csv):\n",
    "    # Replace the text labels with numbers for all target columns\n",
    "    target_columns = train_csv.columns[1:]  # Exclude 'study_id' column\n",
    "    for col in target_columns:\n",
    "        train_csv[col] = train_csv[col].map(label_map)\n",
    "    \n",
    "    # Fill any remaining NaN values with 0.0\n",
    "    train_csv.fillna(0.0, inplace=True)\n",
    "    \n",
    "    return train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c98b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.649546Z",
     "iopub.status.busy": "2024-10-06T08:43:39.649046Z",
     "iopub.status.idle": "2024-10-06T08:43:39.747785Z",
     "shell.execute_reply": "2024-10-06T08:43:39.746159Z"
    },
    "papermill": {
     "duration": 0.11958,
     "end_time": "2024-10-06T08:43:39.753499",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.633919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv[col] = train_csv[col].map(label_map)\n",
      "/tmp/ipykernel_17/887935434.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_csv.fillna(0.0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11340341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11943292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13317052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22191399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26342422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29931867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33736057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38281420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40745534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41477684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44060036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46494080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>52397721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>52695609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53418228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    study_id  spinal_canal_stenosis_l1_l2  spinal_canal_stenosis_l2_l3  \\\n",
       "0    4003253                          0.0                          0.0   \n",
       "1    4646740                          0.0                          0.0   \n",
       "2    7143189                          0.0                          0.0   \n",
       "3    8785691                          0.0                          0.0   \n",
       "4   10728036                          0.0                          0.0   \n",
       "5   11340341                          0.0                          0.0   \n",
       "6   11943292                          0.0                          0.0   \n",
       "7   13317052                          0.0                          0.0   \n",
       "8   22191399                          0.0                          0.0   \n",
       "9   26342422                          0.0                          0.0   \n",
       "10  29931867                          0.0                          1.0   \n",
       "11  33736057                          0.0                          0.0   \n",
       "12  38281420                          0.0                          0.0   \n",
       "13  40745534                          0.0                          0.0   \n",
       "14  41477684                          0.0                          1.0   \n",
       "15  44060036                          0.0                          0.0   \n",
       "16  46494080                          0.0                          0.0   \n",
       "17  52397721                          0.0                          2.0   \n",
       "18  52695609                          0.0                          1.0   \n",
       "19  53418228                          0.0                          0.0   \n",
       "\n",
       "    spinal_canal_stenosis_l3_l4  spinal_canal_stenosis_l4_l5  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           1.0                          2.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "5                           0.0                          0.0   \n",
       "6                           0.0                          0.0   \n",
       "7                           0.0                          0.0   \n",
       "8                           0.0                          2.0   \n",
       "9                           0.0                          0.0   \n",
       "10                          1.0                          0.0   \n",
       "11                          0.0                          0.0   \n",
       "12                          0.0                          1.0   \n",
       "13                          1.0                          2.0   \n",
       "14                          1.0                          2.0   \n",
       "15                          0.0                          0.0   \n",
       "16                          1.0                          0.0   \n",
       "17                          2.0                          1.0   \n",
       "18                          1.0                          0.0   \n",
       "19                          0.0                          0.0   \n",
       "\n",
       "    spinal_canal_stenosis_l5_s1  left_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                           0.0                                    0.0   \n",
       "1                           0.0                                    0.0   \n",
       "2                           0.0                                    0.0   \n",
       "3                           0.0                                    0.0   \n",
       "4                           0.0                                    0.0   \n",
       "5                           0.0                                    0.0   \n",
       "6                           0.0                                    0.0   \n",
       "7                           0.0                                    0.0   \n",
       "8                           0.0                                    0.0   \n",
       "9                           0.0                                    0.0   \n",
       "10                          0.0                                    0.0   \n",
       "11                          0.0                                    0.0   \n",
       "12                          0.0                                    0.0   \n",
       "13                          0.0                                    0.0   \n",
       "14                          0.0                                    0.0   \n",
       "15                          0.0                                    0.0   \n",
       "16                          0.0                                    0.0   \n",
       "17                          0.0                                    0.0   \n",
       "18                          0.0                                    0.0   \n",
       "19                          0.0                                    0.0   \n",
       "\n",
       "    left_neural_foraminal_narrowing_l2_l3  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "5                                     0.0   \n",
       "6                                     0.0   \n",
       "7                                     0.0   \n",
       "8                                     0.0   \n",
       "9                                     0.0   \n",
       "10                                    0.0   \n",
       "11                                    0.0   \n",
       "12                                    0.0   \n",
       "13                                    0.0   \n",
       "14                                    0.0   \n",
       "15                                    0.0   \n",
       "16                                    0.0   \n",
       "17                                    0.0   \n",
       "18                                    1.0   \n",
       "19                                    0.0   \n",
       "\n",
       "    left_neural_foraminal_narrowing_l3_l4  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "5                                     0.0   \n",
       "6                                     0.0   \n",
       "7                                     0.0   \n",
       "8                                     0.0   \n",
       "9                                     0.0   \n",
       "10                                    0.0   \n",
       "11                                    0.0   \n",
       "12                                    0.0   \n",
       "13                                    0.0   \n",
       "14                                    1.0   \n",
       "15                                    0.0   \n",
       "16                                    0.0   \n",
       "17                                    0.0   \n",
       "18                                    1.0   \n",
       "19                                    0.0   \n",
       "\n",
       "    left_neural_foraminal_narrowing_l4_l5  ...  \\\n",
       "0                                     1.0  ...   \n",
       "1                                     1.0  ...   \n",
       "2                                     0.0  ...   \n",
       "3                                     1.0  ...   \n",
       "4                                     0.0  ...   \n",
       "5                                     0.0  ...   \n",
       "6                                     0.0  ...   \n",
       "7                                     1.0  ...   \n",
       "8                                     0.0  ...   \n",
       "9                                     0.0  ...   \n",
       "10                                    1.0  ...   \n",
       "11                                    0.0  ...   \n",
       "12                                    1.0  ...   \n",
       "13                                    1.0  ...   \n",
       "14                                    1.0  ...   \n",
       "15                                    0.0  ...   \n",
       "16                                    0.0  ...   \n",
       "17                                    1.0  ...   \n",
       "18                                    1.0  ...   \n",
       "19                                    0.0  ...   \n",
       "\n",
       "    left_subarticular_stenosis_l1_l2  left_subarticular_stenosis_l2_l3  \\\n",
       "0                                0.0                               0.0   \n",
       "1                                0.0                               0.0   \n",
       "2                                0.0                               0.0   \n",
       "3                                0.0                               0.0   \n",
       "4                                0.0                               0.0   \n",
       "5                                0.0                               0.0   \n",
       "6                                0.0                               0.0   \n",
       "7                                0.0                               0.0   \n",
       "8                                0.0                               0.0   \n",
       "9                                0.0                               0.0   \n",
       "10                               0.0                               0.0   \n",
       "11                               0.0                               0.0   \n",
       "12                               0.0                               0.0   \n",
       "13                               0.0                               0.0   \n",
       "14                               1.0                               1.0   \n",
       "15                               0.0                               0.0   \n",
       "16                               0.0                               0.0   \n",
       "17                               0.0                               1.0   \n",
       "18                               0.0                               1.0   \n",
       "19                               0.0                               0.0   \n",
       "\n",
       "    left_subarticular_stenosis_l3_l4  left_subarticular_stenosis_l4_l5  \\\n",
       "0                                0.0                               1.0   \n",
       "1                                0.0                               2.0   \n",
       "2                                0.0                               0.0   \n",
       "3                                0.0                               0.0   \n",
       "4                                0.0                               0.0   \n",
       "5                                1.0                               1.0   \n",
       "6                                0.0                               0.0   \n",
       "7                                0.0                               0.0   \n",
       "8                                0.0                               1.0   \n",
       "9                                0.0                               0.0   \n",
       "10                               1.0                               1.0   \n",
       "11                               0.0                               0.0   \n",
       "12                               0.0                               0.0   \n",
       "13                               1.0                               2.0   \n",
       "14                               2.0                               2.0   \n",
       "15                               0.0                               0.0   \n",
       "16                               0.0                               1.0   \n",
       "17                               1.0                               2.0   \n",
       "18                               1.0                               1.0   \n",
       "19                               0.0                               0.0   \n",
       "\n",
       "    left_subarticular_stenosis_l5_s1  right_subarticular_stenosis_l1_l2  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "5                                0.0                                0.0   \n",
       "6                                1.0                                0.0   \n",
       "7                                0.0                                0.0   \n",
       "8                                1.0                                0.0   \n",
       "9                                0.0                                0.0   \n",
       "10                               1.0                                1.0   \n",
       "11                               0.0                                0.0   \n",
       "12                               0.0                                0.0   \n",
       "13                               1.0                                0.0   \n",
       "14                               0.0                                0.0   \n",
       "15                               0.0                                0.0   \n",
       "16                               1.0                                0.0   \n",
       "17                               0.0                                0.0   \n",
       "18                               0.0                                0.0   \n",
       "19                               0.0                                0.0   \n",
       "\n",
       "    right_subarticular_stenosis_l2_l3  right_subarticular_stenosis_l3_l4  \\\n",
       "0                                 0.0                                0.0   \n",
       "1                                 1.0                                1.0   \n",
       "2                                 0.0                                0.0   \n",
       "3                                 0.0                                0.0   \n",
       "4                                 0.0                                0.0   \n",
       "5                                 0.0                                1.0   \n",
       "6                                 0.0                                0.0   \n",
       "7                                 0.0                                1.0   \n",
       "8                                 0.0                                0.0   \n",
       "9                                 0.0                                0.0   \n",
       "10                                2.0                                2.0   \n",
       "11                                0.0                                0.0   \n",
       "12                                1.0                                1.0   \n",
       "13                                0.0                                1.0   \n",
       "14                                1.0                                2.0   \n",
       "15                                0.0                                1.0   \n",
       "16                                0.0                                1.0   \n",
       "17                                0.0                                2.0   \n",
       "18                                1.0                                0.0   \n",
       "19                                0.0                                0.0   \n",
       "\n",
       "    right_subarticular_stenosis_l4_l5  right_subarticular_stenosis_l5_s1  \n",
       "0                                 0.0                                0.0  \n",
       "1                                 1.0                                0.0  \n",
       "2                                 0.0                                0.0  \n",
       "3                                 0.0                                0.0  \n",
       "4                                 1.0                                0.0  \n",
       "5                                 1.0                                0.0  \n",
       "6                                 0.0                                0.0  \n",
       "7                                 1.0                                1.0  \n",
       "8                                 2.0                                1.0  \n",
       "9                                 0.0                                0.0  \n",
       "10                                1.0                                2.0  \n",
       "11                                0.0                                0.0  \n",
       "12                                2.0                                2.0  \n",
       "13                                2.0                                0.0  \n",
       "14                                2.0                                0.0  \n",
       "15                                1.0                                0.0  \n",
       "16                                1.0                                0.0  \n",
       "17                                2.0                                0.0  \n",
       "18                                1.0                                0.0  \n",
       "19                                0.0                                0.0  \n",
       "\n",
       "[20 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = prepare_labels(df_train_20)\n",
    "\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df930287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.786120Z",
     "iopub.status.busy": "2024-10-06T08:43:39.784807Z",
     "iopub.status.idle": "2024-10-06T08:43:39.791332Z",
     "shell.execute_reply": "2024-10-06T08:43:39.789526Z"
    },
    "papermill": {
     "duration": 0.025638,
     "end_time": "2024-10-06T08:43:39.794320",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.768682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img_width, img_height = 128, 128\n",
    "# depth = 50  # Number of slices per 3D image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c3393",
   "metadata": {
    "papermill": {
     "duration": 0.013446,
     "end_time": "2024-10-06T08:43:39.822125",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.808679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "NEED TO RESIZE IMAGES TO STANDARD SIZE YET RESIZE BOUDING BOXES CORRECTLY TO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f909240c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.852456Z",
     "iopub.status.busy": "2024-10-06T08:43:39.851941Z",
     "iopub.status.idle": "2024-10-06T08:43:39.865950Z",
     "shell.execute_reply": "2024-10-06T08:43:39.864146Z"
    },
    "papermill": {
     "duration": 0.032904,
     "end_time": "2024-10-06T08:43:39.869116",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.836212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image_dir = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n",
    "\n",
    "# def load_images(df_filtered, image_dir, depth=50, target_size=(128,128)):\n",
    "#     images = []\n",
    "#     max_height = 0\n",
    "#     max_width = 0\n",
    "    \n",
    "#     # Loop through each study_id in df_filtered\n",
    "#     for study_id in df_filtered['study_id'].unique():\n",
    "#         study_filtered = df_filtered[df_filtered['study_id'] == study_id]\n",
    "        \n",
    "#         print(f'study id: {study_id}')\n",
    "\n",
    "#         # Path to the study directory\n",
    "#         study_id_path = os.path.join(image_dir, str(study_id))\n",
    "        \n",
    "#         # Ensure the study path exists\n",
    "#         if not os.path.isdir(study_id_path):\n",
    "#             continue\n",
    "\n",
    "#         # Get the ordered series IDs (this should be based on a specific ordering logic)\n",
    "#         series_ids_ordered = study_filtered['series_id'].unique()\n",
    "\n",
    "#         # Loop through each ordered series_id\n",
    "#         for series_id in series_ids_ordered:\n",
    "#             series_id_path = os.path.join(study_id_path, str(series_id))\n",
    "            \n",
    "#             # Check if the series_id folder exists\n",
    "#             if not os.path.isdir(series_id_path):\n",
    "#                 continue\n",
    "\n",
    "#             # List and sort all DICOM files in the current series_id folder\n",
    "#             dicom_files = [f for f in os.listdir(series_id_path) if f.endswith('.dcm')]\n",
    "#             dicom_files = sorted(dicom_files, key=lambda x: int(x.replace('.dcm', '')))\n",
    "\n",
    "#             # Filter labels for the current series_id\n",
    "#             df_series_filtered = study_filtered[study_filtered['series_id'] == series_id]\n",
    "\n",
    "#             # Skip if no relevant labels exist for this series_id\n",
    "#             if df_series_filtered.empty:\n",
    "#                 continue\n",
    "            \n",
    "#             print(f'series id: {series_id}')\n",
    "            \n",
    "#             # Get the series description (assume it's the same for all files in the series_id)\n",
    "#             series_description = df_series_filtered['series_description'].iloc[0]\n",
    "            \n",
    "#             print(f'{series_description}')\n",
    "            \n",
    "#             stacked_images = []\n",
    "#             processed_instance_numbers = set()  # Track unique instance_numbers\n",
    "\n",
    "#             # Loop through each DICOM file in the series_id folder\n",
    "#             for dicom_file in dicom_files:\n",
    "#                 dicom_path = os.path.join(series_id_path, dicom_file)\n",
    "\n",
    "#                 # Read the DICOM file\n",
    "#                 dicom_data = pydicom.dcmread(dicom_path)\n",
    "\n",
    "#                 # Access the pixel data\n",
    "#                 image_data = dicom_data.pixel_array\n",
    "\n",
    "#                 # Convert the pixel data to 8-bit image for OpenCV\n",
    "#                 image_8bit = cv2.normalize(image_data, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "#                 # Convert grayscale image to 3-channel BGR format for colored annotations\n",
    "#                 image_bgr = cv2.cvtColor(image_8bit, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#                 # Get the corresponding instance number (matching the DICOM file)\n",
    "#                 instance_number = int(dicom_file.replace('.dcm', ''))\n",
    "\n",
    "#                 # Skip if the instance_number has already been processed\n",
    "#                 if instance_number in processed_instance_numbers:\n",
    "#                     continue\n",
    "\n",
    "#                 # Get the rows in df_series_filtered that match this instance_number\n",
    "#                 relevant_labels = df_series_filtered[df_series_filtered['instance_number'] == instance_number]\n",
    "\n",
    "#                 # If there are no relevant labels for this instance, skip the image\n",
    "#                 if relevant_labels.empty:\n",
    "#                     continue\n",
    "                    \n",
    "#                 # Get original dimensions\n",
    "#                 original_height, original_width = image_bgr.shape[:2]\n",
    "\n",
    "#                 # Resize the image to the target size (128x128)\n",
    "#                 resized_image_bgr = cv2.resize(image_bgr, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "#                 # Calculate the scaling factors for width and height\n",
    "#                 scale_x = target_size[1] / original_width\n",
    "#                 scale_y = target_size[0] / original_height\n",
    "\n",
    "#                 # Draw circles at the x, y coordinates in the labels\n",
    "#                 for _, row in relevant_labels.iterrows():\n",
    "#                     x, y = int(row['x']), int(row['y'])\n",
    "#                     # Draw the circle on the image (with a radius of 10, color red, and thickness 2)\n",
    "#                     cv2.circle(image_bgr, (x, y), radius=10, color=(255, 255, 255), thickness=2)\n",
    "#                     # Display the image with circles using matplotlib (optional for visual inspection)\n",
    "                    \n",
    "#                     # Scale the coordinates based on the resizing\n",
    "#                     scaled_x = int(x * scale_x)\n",
    "#                     scaled_y = int(y * scale_y)\n",
    "\n",
    "#                     # Draw the circle on the resized image (with a radius of 10, color red, and thickness 2)\n",
    "#                     cv2.circle(resized_image_bgr, (scaled_x, scaled_y), radius=10, color=(0, 0, 255), thickness=2)\n",
    "                    \n",
    "#                 plt.figure()\n",
    "#                 plt.imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
    "#                 plt.title(f'{dicom_file} - {series_description}')\n",
    "#                 plt.show()\n",
    "\n",
    "#                 # Track maximum width and height of images for later padding\n",
    "#                 max_height = max(max_height, image_bgr.shape[0])\n",
    "#                 max_width = max(max_width, image_bgr.shape[1])\n",
    "\n",
    "#                 # Append the processed image to the stacked_images list (only once per unique instance_number)\n",
    "#                 stacked_images.append(image_bgr)\n",
    "#                 processed_instance_numbers.add(instance_number)\n",
    "                \n",
    "#             # Stack the images to create a 3D array for this series_id\n",
    "#             if stacked_images:\n",
    "#                 stacked_images_np = np.stack(stacked_images, axis=-1)\n",
    "\n",
    "#                 # If the number of slices is less than depth, pad with zeros\n",
    "#                 if stacked_images_np.shape[-1] < depth:\n",
    "#                     pad_width = depth - stacked_images_np.shape[-1]\n",
    "#                     stacked_images_np = np.pad(stacked_images_np, \n",
    "#                                                ((0, 0), (0, 0), (0, 0), (0, pad_width)), \n",
    "#                                                mode='constant')\n",
    "#                 # If more slices, trim the stack\n",
    "#                 else:\n",
    "#                     stacked_images_np = stacked_images_np[:, :, :, :depth]\n",
    "\n",
    "#                 images.append(stacked_images_np)\n",
    "\n",
    "#     # Final padding to ensure all images have the same height and width\n",
    "#     padded_images = []\n",
    "#     for img in images:\n",
    "#         height_pad = max_height - img.shape[0]\n",
    "#         width_pad = max_width - img.shape[1]\n",
    "\n",
    "#         padded_img = np.pad(img, \n",
    "#                             ((0, height_pad), (0, width_pad), (0, 0), (0, 0)),  # Pad height and width dimensions\n",
    "#                             mode='constant')\n",
    "#         padded_images.append(padded_img)\n",
    "\n",
    "#     return np.array(padded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c1be228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.900182Z",
     "iopub.status.busy": "2024-10-06T08:43:39.899514Z",
     "iopub.status.idle": "2024-10-06T08:43:39.912092Z",
     "shell.execute_reply": "2024-10-06T08:43:39.910744Z"
    },
    "papermill": {
     "duration": 0.031662,
     "end_time": "2024-10-06T08:43:39.915013",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.883351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #TO CHECK ALL IMAGES HAVE POSITION AND BOUNDING BOXES \n",
    "\n",
    "# image_dir = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n",
    "\n",
    "# def load_images(df_filtered, image_dir, target_size=(128, 128), depth=50):\n",
    "#     images = []\n",
    "#     max_height = 0\n",
    "#     max_width = 0\n",
    "    \n",
    "#     # Loop through each study_id in df_filtered\n",
    "#     for study_id in df_filtered['study_id'].unique():\n",
    "#         study_filtered = df_filtered[df_filtered['study_id'] == study_id]\n",
    "        \n",
    "#         print(f'study id: {study_id}')\n",
    "\n",
    "#         # Path to the study directory\n",
    "#         study_id_path = os.path.join(image_dir, str(study_id))\n",
    "        \n",
    "#         # Ensure the study path exists\n",
    "#         if not os.path.isdir(study_id_path):\n",
    "#             continue\n",
    "\n",
    "#         # Get the ordered series IDs (this should be based on a specific ordering logic)\n",
    "#         series_ids_ordered = study_filtered['series_id'].unique()\n",
    "\n",
    "#         # Loop through each ordered series_id\n",
    "#         for series_id in series_ids_ordered:\n",
    "#             series_id_path = os.path.join(study_id_path, str(series_id))\n",
    "            \n",
    "#             # Check if the series_id folder exists\n",
    "#             if not os.path.isdir(series_id_path):\n",
    "#                 continue\n",
    "\n",
    "#             # List and sort all DICOM files in the current series_id folder\n",
    "#             dicom_files = [f for f in os.listdir(series_id_path) if f.endswith('.dcm')]\n",
    "#             dicom_files = sorted(dicom_files, key=lambda x: int(x.replace('.dcm', '')))\n",
    "\n",
    "#             # Filter labels for the current series_id\n",
    "#             df_series_filtered = study_filtered[study_filtered['series_id'] == series_id]\n",
    "\n",
    "#             # Skip if no relevant labels exist for this series_id\n",
    "#             if df_series_filtered.empty:\n",
    "#                 continue\n",
    "            \n",
    "#             print(f'series id: {series_id}')\n",
    "            \n",
    "#             # Get the series description (assume it's the same for all files in the series_id)\n",
    "#             series_description = df_series_filtered['series_description'].iloc[0]\n",
    "            \n",
    "#             print(f'{series_description}')\n",
    "            \n",
    "#             stacked_images = []\n",
    "#             processed_instance_numbers = set()  # Track unique instance_numbers\n",
    "\n",
    "#             # Loop through each DICOM file in the series_id folder\n",
    "#             for dicom_file in dicom_files:\n",
    "#                 dicom_path = os.path.join(series_id_path, dicom_file)\n",
    "\n",
    "#                 # Read the DICOM file\n",
    "#                 dicom_data = pydicom.dcmread(dicom_path)\n",
    "\n",
    "#                 # Access the pixel data\n",
    "#                 image_data = dicom_data.pixel_array\n",
    "\n",
    "#                 # Convert the pixel data to 8-bit image for OpenCV\n",
    "#                 image_8bit = cv2.normalize(image_data, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "#                 # Convert grayscale image to 3-channel BGR format for colored annotations\n",
    "#                 image_bgr = cv2.cvtColor(image_8bit, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#                 # Get the corresponding instance number (matching the DICOM file)\n",
    "#                 instance_number = int(dicom_file.replace('.dcm', ''))\n",
    "\n",
    "#                 # Skip if the instance_number has already been processed\n",
    "#                 if instance_number in processed_instance_numbers:\n",
    "#                     continue\n",
    "\n",
    "#                 # Get the rows in df_series_filtered that match this instance_number\n",
    "#                 relevant_labels = df_series_filtered[df_series_filtered['instance_number'] == instance_number]\n",
    "\n",
    "#                 # If there are no relevant labels for this instance, skip the image\n",
    "#                 if relevant_labels.empty:\n",
    "#                     continue\n",
    "\n",
    "#                 # Draw circles at the x, y coordinates in the labels\n",
    "#                 for _, row in relevant_labels.iterrows():\n",
    "#                     x, y = int(row['x']), int(row['y'])\n",
    "#                     # Draw the circle on the image (with a radius of 10, color red, and thickness 2)\n",
    "#                     cv2.circle(image_bgr, (x, y), radius=10, color=(0, 0, 255), thickness=2)\n",
    "#                     # Display the image with circles using matplotlib (optional for visual inspection)\n",
    "#                 plt.figure()\n",
    "#                 plt.imshow(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
    "#                 plt.title(f'{dicom_file} - {series_description}')\n",
    "#                 plt.show()\n",
    "\n",
    "#                 # Track maximum width and height of images for later padding\n",
    "#                 max_height = max(max_height, image_bgr.shape[0])\n",
    "#                 max_width = max(max_width, image_bgr.shape[1])\n",
    "\n",
    "#                 # Append the processed image to the stacked_images list (only once per unique instance_number)\n",
    "#                 stacked_images.append(image_bgr)\n",
    "#                 processed_instance_numbers.add(instance_number)\n",
    "                \n",
    "#             # Stack the images to create a 3D array for this series_id\n",
    "#             if stacked_images:\n",
    "#                 stacked_images_np = np.stack(stacked_images, axis=-1)\n",
    "\n",
    "#                 # If the number of slices is less than depth, pad with zeros\n",
    "#                 if stacked_images_np.shape[-1] < depth:\n",
    "#                     pad_width = depth - stacked_images_np.shape[-1]\n",
    "#                     stacked_images_np = np.pad(stacked_images_np, \n",
    "#                                                ((0, 0), (0, 0), (0, 0), (0, pad_width)), \n",
    "#                                                mode='constant')\n",
    "#                 # If more slices, trim the stack\n",
    "#                 else:\n",
    "#                     stacked_images_np = stacked_images_np[:, :, :, :depth]\n",
    "\n",
    "#                 images.append(stacked_images_np)\n",
    "\n",
    "#     # Final padding to ensure all images have the same height and width\n",
    "#     padded_images = []\n",
    "#     for img in images:\n",
    "#         height_pad = max_height - img.shape[0]\n",
    "#         width_pad = max_width - img.shape[1]\n",
    "\n",
    "#         padded_img = np.pad(img, \n",
    "#                             ((0, height_pad), (0, width_pad), (0, 0), (0, 0)),  # Pad height and width dimensions\n",
    "#                             mode='constant')\n",
    "#         padded_images.append(padded_img)\n",
    "\n",
    "#     return np.array(padded_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877a7471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.946032Z",
     "iopub.status.busy": "2024-10-06T08:43:39.945507Z",
     "iopub.status.idle": "2024-10-06T08:43:39.955587Z",
     "shell.execute_reply": "2024-10-06T08:43:39.954249Z"
    },
    "papermill": {
     "duration": 0.02947,
     "end_time": "2024-10-06T08:43:39.958558",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.929088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # TO CHECK ALL IMAGES HAVE POSITION AND BOUDING BOXES REDRAWN, BUT HAVING DIFF SHAPES\n",
    "\n",
    "# def load_images(df_filtered, image_dir, depth=50, target_size=(128,128)):\n",
    "#     images = []\n",
    "#     max_height = 0\n",
    "#     max_width = 0\n",
    "    \n",
    "#     for study_id in df_filtered['study_id'].unique():\n",
    "#         study_filtered = df_filtered[df_filtered['study_id'] == study_id]\n",
    "#         print(f'study id: {study_id}')\n",
    "#         study_id_path = os.path.join(image_dir, str(study_id))\n",
    "        \n",
    "#         if not os.path.isdir(study_id_path):\n",
    "#             continue\n",
    "\n",
    "#         series_ids_ordered = study_filtered['series_id'].unique()\n",
    "#         for series_id in series_ids_ordered:\n",
    "#             series_id_path = os.path.join(study_id_path, str(series_id))\n",
    "            \n",
    "#             if not os.path.isdir(series_id_path):\n",
    "#                 continue\n",
    "\n",
    "#             dicom_files = [f for f in os.listdir(series_id_path) if f.endswith('.dcm')]\n",
    "#             dicom_files = sorted(dicom_files, key=lambda x: int(x.replace('.dcm', '')))\n",
    "\n",
    "#             df_series_filtered = study_filtered[study_filtered['series_id'] == series_id]\n",
    "\n",
    "#             if df_series_filtered.empty:\n",
    "#                 continue\n",
    "            \n",
    "#             print(f'series id: {series_id}')\n",
    "#             series_description = df_series_filtered['series_description'].iloc[0]\n",
    "#             print(f'{series_description}')\n",
    "            \n",
    "#             stacked_images = []\n",
    "#             processed_instance_numbers = set()\n",
    "\n",
    "#             for dicom_file in dicom_files:\n",
    "#                 dicom_path = os.path.join(series_id_path, dicom_file)\n",
    "#                 dicom_data = pydicom.dcmread(dicom_path)\n",
    "#                 image_data = dicom_data.pixel_array\n",
    "#                 image_8bit = cv2.normalize(image_data, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "                \n",
    "#                 # Convert to grayscale (1 channel)\n",
    "#                 image_gray = image_8bit\n",
    "                \n",
    "#                 # Resize to the target size (128, 128)\n",
    "#                 resized_image_gray = cv2.resize(image_gray, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "#                 instance_number = int(dicom_file.replace('.dcm', ''))\n",
    "\n",
    "#                 if instance_number in processed_instance_numbers:\n",
    "#                     continue\n",
    "\n",
    "#                 relevant_labels = df_series_filtered[df_series_filtered['instance_number'] == instance_number]\n",
    "\n",
    "#                 if relevant_labels.empty:\n",
    "#                     continue\n",
    "\n",
    "#                 for _, row in relevant_labels.iterrows():\n",
    "#                     x, y = int(row['x']), int(row['y'])\n",
    "#                     scaled_x = int(x * (target_size[1] / image_gray.shape[1]))\n",
    "#                     scaled_y = int(y * (target_size[0] / image_gray.shape[0]))\n",
    "#                     cv2.circle(resized_image_gray, (scaled_x, scaled_y), radius=10, color=255, thickness=2)\n",
    "\n",
    "#                 plt.figure()\n",
    "#                 plt.imshow(resized_image_gray, cmap='gray')\n",
    "#                 plt.title(f'{dicom_file} - {series_description}')\n",
    "#                 plt.show()\n",
    "                \n",
    "#                 stacked_images.append(resized_image_gray)\n",
    "#                 processed_instance_numbers.add(instance_number)\n",
    "            \n",
    "#             if stacked_images:\n",
    "#                 stacked_images_np = np.stack(stacked_images, axis=-1)\n",
    "\n",
    "#                 if stacked_images_np.shape[-1] < depth:\n",
    "#                     pad_width = depth - stacked_images_np.shape[-1]\n",
    "#                     stacked_images_np = np.pad(stacked_images_np, ((0, 0), (0, 0), (0, pad_width)), mode='constant')\n",
    "#                 else:\n",
    "#                     stacked_images_np = stacked_images_np[:, :, :depth]\n",
    "\n",
    "#                 images.append(stacked_images_np)\n",
    "\n",
    "#     padded_images = []\n",
    "#     for img in images:\n",
    "#         height_pad = target_size[0] - img.shape[0]\n",
    "#         width_pad = target_size[1] - img.shape[1]\n",
    "\n",
    "#         padded_img = np.pad(img, ((0, height_pad), (0, width_pad), (0, 0)), mode='constant')\n",
    "        \n",
    "#         # Add a new axis for the single channel (grayscale)\n",
    "#         padded_img = np.expand_dims(padded_img, axis=-2)\n",
    "        \n",
    "#         padded_images.append(padded_img)\n",
    "\n",
    "#     return np.array(padded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f34113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:43:39.989494Z",
     "iopub.status.busy": "2024-10-06T08:43:39.988921Z",
     "iopub.status.idle": "2024-10-06T08:44:15.697739Z",
     "shell.execute_reply": "2024-10-06T08:44:15.696024Z"
    },
    "papermill": {
     "duration": 35.729078,
     "end_time": "2024-10-06T08:44:15.701910",
     "exception": false,
     "start_time": "2024-10-06T08:43:39.972832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study ID: 4003253\n",
      "Series ID: 702807833\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 1054713880\n",
      "Description: Sagittal T1\n",
      "Series ID: 2448190387\n",
      "Description: Axial T2\n",
      "Study ID: 4646740\n",
      "Series ID: 3666319702\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 3486248476\n",
      "Description: Sagittal T1\n",
      "Series ID: 3201256954\n",
      "Description: Axial T2\n",
      "Study ID: 7143189\n",
      "Series ID: 132939515\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 3219733239\n",
      "Description: Sagittal T1\n",
      "Series ID: 1951927562\n",
      "Description: Axial T2\n",
      "Study ID: 8785691\n",
      "Series ID: 481125819\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 1570286759\n",
      "Description: Sagittal T1\n",
      "Series ID: 2406919186\n",
      "Description: Axial T2\n",
      "Study ID: 10728036\n",
      "Series ID: 3491739931\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 2399638375\n",
      "Description: Sagittal T1\n",
      "Series ID: 142859125\n",
      "Description: Axial T2\n",
      "Series ID: 2073726394\n",
      "Description: Axial T2\n",
      "Study ID: 11340341\n",
      "Series ID: 3543553307\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 2231042680\n",
      "Description: Sagittal T1\n",
      "Series ID: 1224932122\n",
      "Description: Axial T2\n",
      "Study ID: 11943292\n",
      "Series ID: 1638921810\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 1212326388\n",
      "Description: Sagittal T1\n",
      "Series ID: 403244853\n",
      "Description: Axial T2\n",
      "Series ID: 3800798510\n",
      "Description: Axial T2\n",
      "Study ID: 13317052\n",
      "Series ID: 2677627096\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 1539051863\n",
      "Description: Sagittal T1\n",
      "Series ID: 2500166693\n",
      "Description: Axial T2\n",
      "Study ID: 22191399\n",
      "Series ID: 3753885158\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 434280813\n",
      "Description: Sagittal T1\n",
      "Series ID: 3687121182\n",
      "Description: Axial T2\n",
      "Study ID: 26342422\n",
      "Series ID: 2528347280\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 226564374\n",
      "Description: Sagittal T1\n",
      "Series ID: 307069509\n",
      "Description: Axial T2\n",
      "Series ID: 1679014482\n",
      "Description: Axial T2\n",
      "Study ID: 29931867\n",
      "Series ID: 1676821058\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 1152175603\n",
      "Description: Sagittal T1\n",
      "Series ID: 231278500\n",
      "Description: Axial T2\n",
      "Series ID: 2261718442\n",
      "Description: Axial T2\n",
      "Study ID: 33736057\n",
      "Series ID: 1379151387\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 758801267\n",
      "Description: Sagittal T1\n",
      "Series ID: 1847558962\n",
      "Description: Axial T2\n",
      "Study ID: 38281420\n",
      "Series ID: 880361156\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 2565838687\n",
      "Description: Sagittal T1\n",
      "Series ID: 1178941473\n",
      "Description: Axial T2\n",
      "Study ID: 40745534\n",
      "Series ID: 3918681171\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 2948359731\n",
      "Description: Sagittal T1\n",
      "Series ID: 1395478236\n",
      "Description: Axial T2\n",
      "Study ID: 41477684\n",
      "Series ID: 2595734107\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 3009399271\n",
      "Description: Sagittal T1\n",
      "Series ID: 3749739759\n",
      "Description: Axial T2\n",
      "Study ID: 44060036\n",
      "Series ID: 3294158542\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 1034241723\n",
      "Description: Sagittal T1\n",
      "Series ID: 2320605986\n",
      "Description: Axial T2\n",
      "Series ID: 3055212151\n",
      "Description: Axial T2\n",
      "Study ID: 46494080\n",
      "Series ID: 1763376930\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 4061588226\n",
      "Description: Sagittal T1\n",
      "Series ID: 1543341132\n",
      "Description: Axial T2\n",
      "Study ID: 52397721\n",
      "Series ID: 2452297573\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 2770638094\n",
      "Description: Sagittal T1\n",
      "Series ID: 3220885418\n",
      "Description: Axial T2\n",
      "Study ID: 52695609\n",
      "Series ID: 32135551\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 3284178089\n",
      "Description: Sagittal T1\n",
      "Series ID: 3778925627\n",
      "Description: Axial T2\n",
      "Series ID: 3993996421\n",
      "Description: Axial T2\n",
      "Study ID: 53418228\n",
      "Series ID: 2698575616\n",
      "Description: Sagittal T2/STIR\n",
      "Series ID: 345993377\n",
      "Description: Sagittal T1\n",
      "Series ID: 1921001089\n",
      "Description: Axial T2\n",
      "Number of images loaded: 20\n",
      "(20, 128, 128, 1, 50)\n"
     ]
    }
   ],
   "source": [
    "#IMAGES WITH POSITION AND BOUNDING BOXES STACKED AT FIXED SHAPE\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_images(df_filtered, image_dir, depth=50, target_size=(128, 128)):\n",
    "    images = []\n",
    "    max_height = 0\n",
    "    max_width = 0\n",
    "    \n",
    "    for study_id in df_filtered['study_id'].unique():\n",
    "        study_filtered = df_filtered[df_filtered['study_id'] == study_id]\n",
    "        print(f'Study ID: {study_id}')\n",
    "        study_id_path = os.path.join(image_dir, str(study_id))\n",
    "        \n",
    "        if not os.path.isdir(study_id_path):\n",
    "            continue\n",
    "        \n",
    "        stacked_images = []\n",
    "        processed_instance_numbers = set()\n",
    "\n",
    "        series_ids_ordered = study_filtered['series_id'].unique()\n",
    "        for series_id in series_ids_ordered:\n",
    "            series_id_path = os.path.join(study_id_path, str(series_id))\n",
    "            \n",
    "            if not os.path.isdir(series_id_path):\n",
    "                continue\n",
    "\n",
    "            dicom_files = [f for f in os.listdir(series_id_path) if f.endswith('.dcm')]\n",
    "            dicom_files = sorted(dicom_files, key=lambda x: int(x.replace('.dcm', '')))\n",
    "            \n",
    "            df_series_filtered = study_filtered[study_filtered['series_id'] == series_id]\n",
    "\n",
    "            if df_series_filtered.empty:\n",
    "                continue\n",
    "            \n",
    "            print(f'Series ID: {series_id}')\n",
    "            series_description = df_series_filtered['series_description'].iloc[0]\n",
    "            print(f'Description: {series_description}')\n",
    "            \n",
    "            for dicom_file in dicom_files:\n",
    "                dicom_path = os.path.join(series_id_path, dicom_file)\n",
    "                dicom_data = pydicom.dcmread(dicom_path)\n",
    "                image_data = dicom_data.pixel_array\n",
    "                image_8bit = cv2.normalize(image_data, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "                \n",
    "                # Convert to grayscale (1 channel)\n",
    "                image_gray = image_8bit\n",
    "                \n",
    "                # Resize to the target size (128, 128)\n",
    "                resized_image_gray = cv2.resize(image_gray, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                instance_number = int(dicom_file.replace('.dcm', ''))\n",
    "\n",
    "                if instance_number in processed_instance_numbers:\n",
    "                    continue\n",
    "\n",
    "                relevant_labels = df_series_filtered[df_series_filtered['instance_number'] == instance_number]\n",
    "\n",
    "                if relevant_labels.empty:\n",
    "                    continue\n",
    "\n",
    "                for _, row in relevant_labels.iterrows():\n",
    "                    x, y = int(row['x']), int(row['y'])\n",
    "                    scaled_x = int(x * (target_size[1] / image_gray.shape[1]))\n",
    "                    scaled_y = int(y * (target_size[0] / image_gray.shape[0]))\n",
    "                    cv2.circle(resized_image_gray, (scaled_x, scaled_y), radius=5, color=255, thickness=2)\n",
    "                \n",
    "#                 plt.figure()\n",
    "#                 plt.imshow(resized_image_gray, cmap='gray')\n",
    "#                 plt.title(f'{dicom_file} - {series_description}')\n",
    "#                 plt.show()\n",
    "                \n",
    "                # Append the resized image to the list for stacking\n",
    "                stacked_images.append(resized_image_gray)\n",
    "                processed_instance_numbers.add(instance_number)\n",
    "\n",
    "        # After processing all series for this study_id, stack the images\n",
    "        if stacked_images:\n",
    "            stacked_images_np = np.stack(stacked_images, axis=-1)\n",
    "\n",
    "            if stacked_images_np.shape[-1] < depth:\n",
    "                pad_width = depth - stacked_images_np.shape[-1]\n",
    "                stacked_images_np = np.pad(stacked_images_np, ((0, 0), (0, 0), (0, pad_width)), mode='constant')\n",
    "            else:\n",
    "                stacked_images_np = stacked_images_np[:, :, :depth]\n",
    "\n",
    "            # Add a new axis for the single channel (grayscale)\n",
    "            stacked_images_np = np.expand_dims(stacked_images_np, axis=-2)\n",
    "            images.append(stacked_images_np)\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "# Assuming df_filtered is already loaded with 'study_id', 'series_id', and 'series_description'\n",
    "X = load_images(df_series_20, image_dir=\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images\")\n",
    "# y = train_csv  # Assuming this contains the corresponding labels for the study_ids\n",
    "\n",
    "# Check if images and labels are loaded correctly\n",
    "print(f\"Number of images loaded: {len(X)}\")\n",
    "# print(f\"Number of labels loaded: {len(y)}\")  # Uncomment when y is available\n",
    "\n",
    "print(X.shape)\n",
    "# print(y.shape)  # Uncomment when y is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d06502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:44:15.744833Z",
     "iopub.status.busy": "2024-10-06T08:44:15.744279Z",
     "iopub.status.idle": "2024-10-06T08:44:15.751003Z",
     "shell.execute_reply": "2024-10-06T08:44:15.749267Z"
    },
    "papermill": {
     "duration": 0.031807,
     "end_time": "2024-10-06T08:44:15.753964",
     "exception": false,
     "start_time": "2024-10-06T08:44:15.722157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Assuming df_filtered is already loaded with 'study_id', 'series_id', and 'series_description'\n",
    "# X = load_images(df_series_30, image_dir=\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images\", \n",
    "#                    img_width=img_width, img_height=img_height, depth=50)\n",
    "\n",
    "# # X = np.squeeze(X, axis=-2)  # Removes the 4th dimension\n",
    "\n",
    "# y = train_csv\n",
    "\n",
    "# # Check if images and labels are loaded correctly\n",
    "# print(f\"Number of images loaded: {len(X)}\")\n",
    "# print(f\"Number of labels loaded: {len(y)}\")\n",
    "\n",
    "# print(X.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8493566b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:44:15.797794Z",
     "iopub.status.busy": "2024-10-06T08:44:15.797307Z",
     "iopub.status.idle": "2024-10-06T08:44:15.808521Z",
     "shell.execute_reply": "2024-10-06T08:44:15.806573Z"
    },
    "papermill": {
     "duration": 0.036724,
     "end_time": "2024-10-06T08:44:15.811410",
     "exception": false,
     "start_time": "2024-10-06T08:44:15.774686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128, 128, 50)\n",
      "(20, 25)\n"
     ]
    }
   ],
   "source": [
    "X = np.squeeze(X, axis=3)\n",
    "y = train_csv.iloc[:, 1:].values  # Targets from train_csv (excluding 'study_id'\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac91ae97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:44:15.858044Z",
     "iopub.status.busy": "2024-10-06T08:44:15.857564Z",
     "iopub.status.idle": "2024-10-06T08:44:15.875339Z",
     "shell.execute_reply": "2024-10-06T08:44:15.874002Z"
    },
    "papermill": {
     "duration": 0.045845,
     "end_time": "2024-10-06T08:44:15.878895",
     "exception": false,
     "start_time": "2024-10-06T08:44:15.833050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now X_train and X_test should have the correct shape for your CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b69b76a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:44:15.924033Z",
     "iopub.status.busy": "2024-10-06T08:44:15.923587Z",
     "iopub.status.idle": "2024-10-06T08:44:15.936121Z",
     "shell.execute_reply": "2024-10-06T08:44:15.934893Z"
    },
    "papermill": {
     "duration": 0.038184,
     "end_time": "2024-10-06T08:44:15.939177",
     "exception": false,
     "start_time": "2024-10-06T08:44:15.900993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "\n",
    "def model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32, (3, 3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a723f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:44:15.984363Z",
     "iopub.status.busy": "2024-10-06T08:44:15.983930Z",
     "iopub.status.idle": "2024-10-06T08:44:15.989937Z",
     "shell.execute_reply": "2024-10-06T08:44:15.988739Z"
    },
    "papermill": {
     "duration": 0.032098,
     "end_time": "2024-10-06T08:44:15.992874",
     "exception": false,
     "start_time": "2024-10-06T08:44:15.960776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 128, 128\n",
    "depth = 50  # Number of slices per 3D image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3876628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-06T08:44:16.038510Z",
     "iopub.status.busy": "2024-10-06T08:44:16.037259Z",
     "iopub.status.idle": "2024-10-06T08:54:48.213923Z",
     "shell.execute_reply": "2024-10-06T08:54:48.212316Z"
    },
    "papermill": {
     "duration": 632.202631,
     "end_time": "2024-10-06T08:54:48.216851",
     "exception": false,
     "start_time": "2024-10-06T08:44:16.014220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7s/step - accuracy: 0.0311 - loss: 16483.3633 - val_accuracy: 0.0000e+00 - val_loss: 153810.5000\n",
      "Epoch 2/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 527342.3750 - val_accuracy: 0.0000e+00 - val_loss: 1773242.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 6682850.0000 - val_accuracy: 0.0000e+00 - val_loss: 26229144.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7s/step - accuracy: 0.0450 - loss: 53008636.0000 - val_accuracy: 0.0000e+00 - val_loss: 162462176.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7s/step - accuracy: 0.0561 - loss: 231726784.0000 - val_accuracy: 0.0000e+00 - val_loss: 562139520.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7s/step - accuracy: 0.0733 - loss: 1148249216.0000 - val_accuracy: 0.0000e+00 - val_loss: 2315204096.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7s/step - accuracy: 0.0000e+00 - loss: 4741925376.0000 - val_accuracy: 0.0000e+00 - val_loss: 7690247168.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7s/step - accuracy: 0.1579 - loss: 14612372480.0000 - val_accuracy: 0.0000e+00 - val_loss: 24641748992.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7s/step - accuracy: 0.1585 - loss: 43358834688.0000 - val_accuracy: 0.0000e+00 - val_loss: 59214241792.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7s/step - accuracy: 0.0746 - loss: 169811017728.0000 - val_accuracy: 0.0000e+00 - val_loss: 179519651840.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f41c4546ad0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the model\n",
    "input_shape = (img_width, img_height, depth, 1)  # Adjusted for 3D input\n",
    "num_classes = 25\n",
    "model = model(input_shape, num_classes)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=2, validation_data=(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 707.062203,
   "end_time": "2024-10-06T08:54:51.091316",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-06T08:43:04.029113",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
